{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/pratikpal1/diabetics-detection-using-various-ml-models?scriptVersionId=108591617\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pandas_profiling as pp\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nimport xgboost\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVC\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n\nimport seaborn as sns\nsns.set_style('whitegrid')\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport scipy.stats as stats\n%matplotlib inline\n\nimport os\n#from IPython.display import Image\n\n#import shutil\n#shutil.rmtree(\"../input/diabetes-dataset\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/diabetes-dataset/diabetes2.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There aren't any blanks and there are 768 records and 9 features\n#### Below is a heatmap to check if there is any blank data","metadata":{}},{"cell_type":"code","source":"sns.heatmap(df.isnull(),yticklabels= False,cbar = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing low Variance Features variance (features with variance less than 0.1)","metadata":{}},{"cell_type":"code","source":"var = df.var()\ncol_name = df.columns\nindex=0\nquasi_const = []\nfor i in var:\n    if i < 0.1:\n        quasi_const.append(col_name[index])\n    index +=1\nprint(quasi_const)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are no columns with variance less than 1 \n\n#### seems the data set is already cleaned and ready to go","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df, hue = 'Outcome')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Checking the distribution of the target column","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=df['Outcome'], hue= df['Outcome'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There are more healthy patients than Diabetic patients, we need to check if that would affect our predictions models\n\n#### Getting a profile report to check the correlations and the awesom visualizations\n\n#### Note: The line '%matplotlib inline' needs to be written after importing pandas_profiling otherwise, we may not be able to see garphs that we plot after using the profile report function","metadata":{}},{"cell_type":"code","source":"pp.ProfileReport(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### BloodPressure is correlated with BMI\n#### Pregnancies are correlated with Age\n#### BloodPressure, SkinThinkness, Insulin cannot be zero, they have to be filled\n#### We will be filling the mean value of the columns for every zero that we get","metadata":{}},{"cell_type":"markdown","source":"## Data Cleanning","metadata":{}},{"cell_type":"markdown","source":"#### From the profile report we could see that the insulin has a large number of zeros, as such lets drop the column.\n#### Also for the features like BloodPressure and SkinThickness 0s are replaced by mean","metadata":{}},{"cell_type":"code","source":"df.drop('Insulin', axis =1, inplace = True)\n\n#for i in ['BloodPressure','SkinThickness','Insulin']:\nfor i in ['BloodPressure','SkinThickness']:\n    df[i].replace(0,np.nan,inplace =True)\n    df[i].fillna(df[i].mean(),inplace = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### some of the features are skewed, we will have to handle this before training the model","metadata":{}},{"cell_type":"code","source":"df.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Visualizing the features for skewness","metadata":{}},{"cell_type":"code","source":"for i in df.columns:\n    if(i != 'Outcome'):\n        plt.figure(figsize = (14,4))\n        plt.subplot(1,2,1)\n        #the figure has 1 row, 2 columns, and this plot is the first (1) plot.\n        sns.histplot(x =df[i], hue = df['Outcome'])\n        plt.title(i)\n    \n        plt.subplot(1,2,2)\n        #the figure has 1 row, 2 columns, and this plot is the second (2) plot.\n        stats.probplot(x =df[i], dist ='norm', plot = plt)               \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Power transform\n#### We will need to normailizing and transforming the features to remove the skewness and resemble the normal distribution\n[![1-LXu-BIQBwor-Bt-Fub0lxp-STg.png](https://i.postimg.cc/63ZSk5fh/1-LXu-BIQBwor-Bt-Fub0lxp-STg.png)](https://postimg.cc/gXYNRp5w)\n#### Here we use 'yeo-johnson' because it can handle the negetive and zero values","metadata":{}},{"cell_type":"code","source":"pt = PowerTransformer(method = 'yeo-johnson')\ndf_pt = pd.DataFrame(data =pt.fit_transform(df.drop('Outcome',axis =1)),columns = df.columns[:-1])\ndf_pt = df_pt.assign(Outcome = df['Outcome'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df_pt.columns:\n    if(i != 'Outcome'):\n        plt.figure(figsize = (14,4))\n        plt.subplot(1,2,1)\n        sns.histplot(x =df_pt[i], hue = df_pt['Outcome'])\n        plt.title(i)\n    \n        plt.subplot(1,2,2)\n        stats.probplot(x =df_pt[i], dist ='norm', plot = plt)               \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The Feature distribution are normalized. This shall help in faster convergence and better results for the logistice regression\n#### Checking the skew for the transformed data","metadata":{}},{"cell_type":"code","source":"df_pt.skew()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df_pt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (16,8))\nsns.heatmap(df.corr(),annot= True, cbar = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine learning","metadata":{}},{"cell_type":"markdown","source":"#### Splitting the data. We will try to train and test all the models on the same sets","metadata":{}},{"cell_type":"code","source":"X = df.drop('Outcome', axis =1)\ny = df['Outcome']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The below block is not necessary as the features had been transformed using power tranformer before","metadata":{}},{"cell_type":"code","source":"#st_sclr = StandardScaler()\n#X_train = pd.DataFrame(st_sclr.fit_transform(X_train),columns = X_train.columns)\n#X_test = pd.DataFrame(st_sclr.fit_transform(X_test),columns = X_test.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plotting the training and testing data","metadata":{}},{"cell_type":"code","source":"for i in X_train.columns:\n    plt.figure(figsize = (14,4))\n    plt.subplot(1,2,1)\n    sns.histplot(X_train[i],color= 'Green')\n    plt.subplot(1,2,2)\n    sns.histplot(X_test[i])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mean_std_train = pd.DataFrame(data = [X_train.mean(), X_train.std()], columns = X_train.columns)\ndf_mean_std_test = pd.DataFrame(data = [X_test.mean(), X_test.std()], columns = X_test.columns)\ndf_mean_std_train.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mean_std_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The mean now is almost 0 and the st dev is close to 1 after scaling the input data\n#### Generally for standard scaling is done on the training data separately, this is done to ensure we don't overfit","metadata":{}},{"cell_type":"markdown","source":"## Logistic Regression","metadata":{}},{"cell_type":"markdown","source":"#### Logistic regression is based on the sigmoid finction f(x) = 1/(1-exp(-x)). \n#### Based on what we enter as 'x' we get a probaility value between 0 and 1. \n#### Based on this value we fix a the threshold on the output (eg: 0.5) for a feature \n#### Below which the value is said to be classified as 0 and above which it is classified as 1\n\n[![images.png](https://i.postimg.cc/v83LQw27/images.png)](https://postimg.cc/BtP1gk0t)","metadata":{}},{"cell_type":"code","source":"lrmodel = LogisticRegression()\n\nlrmodel.fit(X_train,y_train)\n\nlr_predict = lrmodel.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### getting the performance of the LR model","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,lr_predict))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,lr_predict)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,lr_predict,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Stratified K-fold cross validation\n#### Which is pretty good\n\n#### Let's check the cross validation scores (Stratified K-fold cross validation).\n#### Here we divide the whole data set into 6 splits and train the model 6 times, taking a different test set each time\n#### We will then take the average of all the accuracy for all the runs\n[![Illustration-of-the-K-Fold-Cross-Validation-Algorithm.jpg](https://i.postimg.cc/F1XhMBSY/Illustration-of-the-K-Fold-Cross-Validation-Algorithm.jpg)](https://postimg.cc/WqSRrSXV)\n#### Here we are taking the entire set of the features and scaling them before applying the cross validation","metadata":{}},{"cell_type":"code","source":"skfold = StratifiedKFold(n_splits = 6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LogisticRegression()\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## K-nearest neighbours","metadata":{}},{"cell_type":"markdown","source":"#### As the name suggest this algorith basically classifies a point based on the class of the neighbouring points. It works with the following steps\n#### 1. Calculate the distant of the point X (the point for which we will predict) to all points in the data \n#### 2. Sort the points in your data by increasing the distance form x\n#### 3. Predict majority label of the k closest points (k is determined by the minimum error rate graph)\n\n#### Note: For smaller k (k=1) we get a lot of variability and noise. \n#### Larger K leades to more bias and low variability, which helps form a boundary at the cost of mislabeling some points\n#### This is not suited for categorical Features\n\n[![0-It-VKiyx2-F3-ZU8z-V5.png](https://i.postimg.cc/NjYHTNnG/0-It-VKiyx2-F3-ZU8z-V5.png)](https://postimg.cc/tYSJGzy8)\n\n#### Here if we take K (the number of neighbours) = 3 the '?' is classified as B but if we take K = 7 the same point would be classified as A.\n#### We carry out this process for multiple values of K and select the value of K for which we get minimum number of deviations","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors =1)\n\nknn.fit(X_train,y_train)\npred_knn= knn.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Predicting results based on KNN with only one neighbor","metadata":{}},{"cell_type":"code","source":"print(classification_report(y_test,pred_knn))\n\n#print(confusion_matrix(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,pred_knn)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,pred_knn,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### number of neighbors = 1 yeild high errors. Thus we have to find the ideal number of neighbours to minimize errors\n\n#### Here I take a empty list called error_rate, fit and train the KNN model for neghbours with 1 to 40 and append the mean number of mismatches between the predicted value and the actual labelled value. KNN is a supervised algorithm","metadata":{}},{"cell_type":"code","source":"error_rate = []\n\nfor i in range(1,40):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred= knn.predict(X_test)\n    error_rate.append(np.mean(pred!= y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.lineplot(x=range(1,40) ,y=error_rate,dashes=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### k =30 seems to yeild resonable errors","metadata":{}},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=30)\nknn.fit(X_train,y_train)\npred = knn.predict(X_test)\n\n#print(classification_report(y_test,pred))\nprint(confusion_matrix(y_test,pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,pred)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,pred,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We obtain 74% accuracy from this model, which isn't enough. Lets go for the stratified K fold cross validation before check out decision trees & random forest","metadata":{}},{"cell_type":"code","source":"model = KNeighborsClassifier(n_neighbors=20)\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There is a large variation in the accuracies obtained while the average accuracy is roughly 75%","metadata":{}},{"cell_type":"markdown","source":"## Decision trees and random forests\n## Decision Trees\n#### Decision Trees consists of root, decision and leaves. We consider the features and split the records on the basis of a feature.\n[![1-z-Mu0-UClot-NXljrjqmy-RIHA.png](https://i.postimg.cc/zv09j2jm/1-z-Mu0-UClot-NXljrjqmy-RIHA.png)](https://postimg.cc/644j60gz)\n#### We consider the purity (based on how clearly the classes are separated) of the daughter nodes after splitting. (Measured through Ginni and Entropy)\n[![1-x5-W-NTWo-Ne-STex-V2-Ps-FICQ.png](https://i.postimg.cc/4N00x921/1-x5-W-NTWo-Ne-STex-V2-Ps-FICQ.png)](https://postimg.cc/1fpBWfQg)\n#### The above is maximizing the information gain","metadata":{}},{"cell_type":"code","source":"dt= DecisionTreeClassifier()\n\ndt.fit(X_train,y_train)\n\npred_dt = dt.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred_dt))\n#print(confusion_matrix(y_test,pred_dt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,pred_dt)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,pred_dt,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This isn't that much better.. maybe random forests will be better, as we have 768 records. \n#### Note: Also the above reults are not consistent.. I got much worse performance on my previous run.\n#### let's do a cross validation to check the variation in accurcy","metadata":{}},{"cell_type":"code","source":"model = DecisionTreeClassifier()\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As expected the mininum is only 69.79% accurate. This is beacuse Decision Trees are fammously prone to overfitting the training set","metadata":{}},{"cell_type":"markdown","source":"## Random Forest","metadata":{}},{"cell_type":"markdown","source":"#### This involves bagging of many of the decision trees (ensamble). Decision trees are suceptable to over fitting\n#### In case of Random Forest we take the features and randomly select some of them to train our trees\n#### The numner of random samples selected for traing trees (m) is the square root of the number of full set of the features (p)\n\n[![images-1.png](https://i.postimg.cc/JhdmcvqS/images-1.png)](https://postimg.cc/McRhzsgY)","metadata":{}},{"cell_type":"code","source":"rfc = RandomForestClassifier()\n\nrfc.fit(X_train,y_train)\n\npred_rfc = rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test,pred_rfc))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,pred_rfc)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,pred_rfc,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This is much better. \n#### Lets try cross validation on this before moving on to SVM","metadata":{}},{"cell_type":"code","source":"model = RandomForestClassifier()\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Though this is the highest average accuracy but there is a significant variation","metadata":{}},{"cell_type":"markdown","source":"## Random Search CV for the Random Forest","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameter Description\n#### bootstraping will enable each tree of the Forest to be trained on a subset of the features instead of all the features at once, this lowers variance\n#### max_depth is the maximum number of levels for the trees\n#### max_features is the number of features to consider when looking for the best split: If int, then consider max_features features at each split.\n#### min_samples_leaf is the minimum number of samples required to be at a leaf node is similar to min_samples_splits, however, this describe the minimum number of samples of samples at the leafs\n#### min_samples_split the minimum number of samples required to split an internal node\n#### n_estimators is the number of individual trees in the forest","metadata":{}},{"cell_type":"code","source":"param_grid = {'bootstrap': [True, False],\n 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n 'max_features': ['auto', 'sqrt'],\n 'min_samples_leaf': [1, 2, 4],\n 'min_samples_split': [2, 5, 10],\n 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfc = RandomForestClassifier()\n\nrand_search_RF = RandomizedSearchCV(estimator = rfc, param_distributions = param_grid, verbose =  1)\n\nrand_search_RF.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_search_RF.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The results are as expect.. We will have to refit the data to a new model (rand_search_RF.best_estimator_) with the above parameters","metadata":{}},{"cell_type":"code","source":"rand_search_RF.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_rfc= RandomForestClassifier(bootstrap=False, max_depth=100, min_samples_leaf=2, min_samples_split=10, n_estimators=800, max_features= 'auto')\nfinal_rfc.fit(X_train,y_train)\nfinal_pred = final_rfc.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(confusion_matrix(y_test,final_pred))\n\nprint(classification_report(y_test,final_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,final_pred)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,final_pred,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = cross_val_score(final_rfc, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Which is only slightly worse over the untuned SVM\n#### Ok, Let's do the 'PCA', it is an attempt to reduce the number of Dimensions.","metadata":{}},{"cell_type":"markdown","source":"## SVM (Support Vector Machines)","metadata":{}},{"cell_type":"markdown","source":"#### Here we draw bounderies in n dimension (n= number of features) which separate the classes.\n#### In case we cannot draw a clear boundary due to overlapping or classes being arranged in concentric circles, we take higher dimensions.\n#### A higher dimension is a feature raised to a power plotted over a new axis (Using Kernals)\n\n[![Support-Vector-Machine-visualization.png](https://i.postimg.cc/g0wc5GnG/Support-Vector-Machine-visualization.png)](https://postimg.cc/kVmdR3QH)\n","metadata":{}},{"cell_type":"code","source":"model = SVC()\n\nmodel.fit(X_train, y_train)\n\nsvm_prediction = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(confusion_matrix(y_test,svm_prediction))\nprint(classification_report(y_test,svm_prediction))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,svm_prediction)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,svm_prediction,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I was hoping this would not be such a high accuracy. Lets check on cross validation and then check tuning the parameters using grid search improves the accuracy","metadata":{}},{"cell_type":"code","source":"model = SVC()\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This has surprisingly given me the second highest accuracy and the least variation","metadata":{}},{"cell_type":"markdown","source":"## Grid Search","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### C controls feedback on misclassification on the training data, thus it increases variability and lowers bias\n#### gamma: it is a parameter in the kernel (which is rbf by default), smaller gamma means a larger variance. ie. a high gamma will increase bias and decrease variability\n#### Low variablilty means the SVM is not doing a good job of fitting the training data (I think). So I think C should be higher and gamma lower than default","metadata":{"execution":{"iopub.status.busy":"2022-09-29T22:15:26.225907Z","iopub.execute_input":"2022-09-29T22:15:26.226624Z","iopub.status.idle":"2022-09-29T22:15:26.231049Z","shell.execute_reply.started":"2022-09-29T22:15:26.226586Z","shell.execute_reply":"2022-09-29T22:15:26.230307Z"}}},{"cell_type":"code","source":"param_grid = {'C':[0.1,1,10,100,1000],'gamma': [1,0.01,0.001,0.0001]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(SVC(), param_grid, verbose =  1)\n\ngrid.fit(X_train,y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_pred = grid.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(confusion_matrix(y_test,grid_pred))\n\nprint(classification_report(y_test,grid_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,grid_pred)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,grid_pred,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GridSearchCV(SVC(), param_grid, verbose =  1)\naccuracy = cross_val_score(model, X, y, cv=skfold)\nprint()\nprint('max',accuracy.max(),' | ','min', accuracy.min(), ' | ','avg',accuracy.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Which is only slightly worse than Random Search CV for Random Forest","metadata":{}},{"cell_type":"markdown","source":"## K means Clustering\n","metadata":{}},{"cell_type":"markdown","source":"\n#### K means is an unsupervised learning algorithm, used to divide data into distinct groups such that observations within each group are similar\n#### Here the data set is labelled, but we are going to ignore the labels\n#### First we have to choose K based on elbow method by plotting labels and SSE (here we will have 2 i.e. diabatic or non-diabatic )\n#### 1. Assign each point to a cluster randomly\n#### Until the clusters stop changing keep doing below:\n#### 2. Calculate the centroid for each cluster by taking mean distance vectors of each point in the cluster\n#### 3. Assign each data point to the cluster for which centroid is closest\n\n[![images-2.png](https://i.postimg.cc/qMXGhTBB/images-2.png)](https://postimg.cc/KRjTwCgC)","metadata":{}},{"cell_type":"code","source":"kmeans =KMeans(n_clusters = 2)\nkmeans.fit(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kmeans.cluster_centers_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"km_pred = kmeans.labels_ \nprint(classification_report(y_test,km_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"con_mat = confusion_matrix(y_test,km_pred)\nplt.figure(figsize=(14,4)) \nplt.subplot(1,2,1)\nsns.heatmap(con_mat/np.sum(con_mat)*100,annot =True)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Class')\nplt.ylabel('Actual Class')\n\nplt.subplot(1,2,2)\nsns.heatmap(pd.DataFrame(classification_report(y_test,km_pred,output_dict=True)).T.iloc[:,:-1], annot = True)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As far a detecting deseases go we are interested in minimizing the false negetives. \n#### K Means provides us with lowest False negetive rates, though this comes at a cost of higher number of false positives","metadata":{}},{"cell_type":"markdown","source":"## PCA","metadata":{}},{"cell_type":"code","source":"# number of dimensions\nprint(df.shape[1] -1)\n\n# name of dimensions\nprint(df.columns.drop('Outcome').values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lets center and scale the data, so that the mean is 0 and standard deviation is 1","metadata":{}},{"cell_type":"code","source":"std_scaler = StandardScaler()\nscaled_data = std_scaler.fit_transform(df.drop('Outcome',axis =1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_feat= pd.DataFrame(scaled_data,columns=df.columns[:-1])\nscaled_feat.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I have a feeling that I have done this before, but we do this again so as to compute the mean and standard variation for all the data set at once\n\n#### Lets try finding 2 componets that contribute most to the end result","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components =2)\n\npca.fit(scaled_feat)\n\nx_pca = pca.transform(scaled_feat)\n\nscaled_feat.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_pca.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### the number of features have been reduced to 2","metadata":{}},{"cell_type":"code","source":"sns.scatterplot(x= x_pca[:,0],y =x_pca[:,1],hue = df['Outcome'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### There isn't a very clear distinction. Also, the first feature(x) and the second feature(y) donot relate 1 to 1 with the features that we had they are more like a combination\n#### we could show this in a heat map","metadata":{}},{"cell_type":"code","source":"df_pca = pd.DataFrame(pca.components_,columns=df.columns[:-1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(df_pca,annot=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The lighter the color the more related the principal component is to the feature","metadata":{}},{"cell_type":"markdown","source":"#### You will have to download the note book and run it.. I am not able to save this with the graphs due to the 1 MB limit.. let me know if there is a way to work around this","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}